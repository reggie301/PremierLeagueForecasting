{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\reggi\\AppData\\Local\\Temp\\ipykernel_4560\\3872274955.py:55: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
      "  a['team'] = a['team'].str.replace('.', '')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n",
      "['2017_2018_Fixture', '2018_2019_Fixture', '2019_2020_Fixture', '2020_2021_Fixture', '2021_2022_Fixture', '2022_2023_Fixture']\n",
      "['2017_2018_SPIdata', '2018_2019_SPIdata', '2019_2020_SPIdata', '2020_2021_SPIdata', '2021_2022_SPIdata', '2022_2023_SPIdata']\n",
      "['2017_2018_Fixture', '2018_2019_Fixture', '2019_2020_Fixture', '2020_2021_Fixture', '2021_2022_Fixture', '2022_2023_Fixture']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\reggi\\AppData\\Local\\Temp\\ipykernel_4560\\3872274955.py:548: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_pred['GF_x'] = 0\n",
      "C:\\Users\\reggi\\AppData\\Local\\Temp\\ipykernel_4560\\3872274955.py:549: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_pred['GA_x'] = 0\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import os\n",
    "from selenium import webdriver\n",
    "import pandas as pd\n",
    "from datetime import date\n",
    "import requests\n",
    "import numpy as np\n",
    "import time\n",
    "import random\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import xgboost as xgb\n",
    "\n",
    "\n",
    "### SPI SCRAPER FOR THIS MATCHWEEK\n",
    "\n",
    "\n",
    "current_season = int(input('What is the current season?'))\n",
    "current_matchweek = int(input('What is the current matchweek?'))\n",
    "\n",
    "\n",
    "url = r'https://projects.fivethirtyeight.com/soccer-predictions/premier-league/'\n",
    "\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "r = driver.get(url) # proxies=proxies\n",
    "time.sleep(2)\n",
    "\n",
    "date_dict = {'Sept':'Sep','March':'Mar','April':'Apr','June':'Jun','July':'Jul'}\n",
    "  \n",
    "if not os.getcwd().endswith('Football Forecasting Version 2'):\n",
    "    os.chdir(os.path.abspath(os.path.join(os.getcwd(), os.pardir)))\n",
    "\n",
    "current_folder = os.getcwd()\n",
    "\n",
    "relative_folder = fr'{current_season}_{current_season+1}_SPIdata'   \n",
    "\n",
    "full_path = os.path.join(current_folder, relative_folder)\n",
    "\n",
    "isExist = os.path.exists(full_path)\n",
    "\n",
    "\n",
    "if not isExist:\n",
    "    os.makedirs(full_path)\n",
    "\n",
    "match_date = date.today().strftime('%y%b%d')\n",
    "\n",
    "dfs = pd.read_html(driver.page_source)\n",
    "a = dfs[0].replace(' ',':')\n",
    "a.columns = a.columns.droplevel()\n",
    "a = a[['team','spi','off.','def.']]\n",
    "a['team'] = a['team'].str.replace('\\d+', '',regex = True)\n",
    "a['team'] = a['team'].str.replace('pts', '')\n",
    "a['team'] = a['team'].str.replace('pt', '')\n",
    "a['team'] = a['team'].str.replace('.', '')\n",
    "a['team'] = a['team'].str.strip()\n",
    "a['date'] = match_date\n",
    "a['date'] = pd.to_datetime(a['date'],format = '%y%b%d')\n",
    "a = a.rename(columns = {'off.':'off','def.':'def'})\n",
    "\n",
    "a.to_csv(fr'{full_path}\\{current_season}_{current_season+1}_{match_date}.csv')\n",
    "\n",
    "driver.close()\n",
    "\n",
    "## FIXTURE SCRAPER FROM FBREF\n",
    "\n",
    "# Iterates through premier league seasons\n",
    "for i in range (current_season, current_season + 1):\n",
    "\n",
    "    # Makes sure we are in the right folder\n",
    "\n",
    "    if not os.getcwd().endswith('Football Forecasting Version 2'):\n",
    "        os.chdir(os.path.abspath(os.path.join(os.getcwd(), os.pardir)))\n",
    "    \n",
    "    current_folder = os.getcwd()\n",
    "\n",
    "    relative_folder = fr'{i}_{i+1}_Fixture'   \n",
    "\n",
    "    full_path = os.path.join(current_folder, relative_folder)\n",
    "\n",
    "    isExist = os.path.exists(full_path)\n",
    "\n",
    "    # Creates fixture folder if it does not exist\n",
    "\n",
    "    if not isExist:\n",
    "        os.makedirs(full_path)\n",
    "\n",
    "    url = fr'https://fbref.com/en/comps/9/{i}-{i+1}/{i}-{i+1}-Premier-League-Stats'\n",
    "\n",
    "    # Uses user-agent to disguise\n",
    "\n",
    "    HEADERS={'User-Agent':'Mozilla/5.0 (iPhone; CPU OS 12_2 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Mobile/15E148'}\n",
    "\n",
    "\n",
    "    # Scrapes fixture data\n",
    "\n",
    "    r = requests.get(url, headers=HEADERS) # proxies=proxies\n",
    "    print(r)\n",
    "    soup = BeautifulSoup(r.text,'html.parser') \n",
    "\n",
    "    List_of_teams = []\n",
    "\n",
    "    time.sleep(2)\n",
    "\n",
    "    Team_partial_link = []\n",
    "    Team_full_link = []\n",
    "\n",
    "    table_soup = soup.find('table', {'class':'stats_table sortable min_width force_mobilize'})\n",
    "\n",
    "    for row in table_soup.find_all('tr'):\n",
    "        row_text = [e.text.strip() for e in row.find_all('td')]\n",
    "        try:\n",
    "            List_of_teams.append(row_text[0])\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "    row_team = table_soup.find_all('td',{'class':'left','data-stat':'team'})\n",
    "\n",
    "    for e in row_team:\n",
    "        a = e.find('a')\n",
    "        Team_partial_link.append(e.find('a').get('href')) \n",
    "\n",
    "    for e in Team_partial_link:\n",
    "        Team_full_link.append('https://fbref.com' + e)\n",
    "\n",
    "    link_dictionary = dict(zip(Team_full_link,List_of_teams,))\n",
    "\n",
    "    for url in Team_full_link:\n",
    "        time.sleep(3)\n",
    "        # try:\n",
    "        r = requests.get(url, headers=HEADERS)\n",
    "        soup = BeautifulSoup(r.text,'html.parser') \n",
    "        table_soup = soup.find('table', {'class':'stats_table sortable min_width','id':'matchlogs_for'})\n",
    "        header_data_fixtures = []\n",
    "        table_data_fixtures = [] \n",
    "        date_list = []\n",
    "        new_fixtures_table_data = []\n",
    "\n",
    "        row = table_soup.find('tr')\n",
    "        header_data_fixtures = [e.text.strip() for e in row.find_all('th')]\n",
    "\n",
    "        for row in table_soup.find_all('tr'):\n",
    "            date_text = [e.text.strip() for e in row.find_all('th',{'class':'left'})]\n",
    "            date_list.append(date_text)\n",
    "            row_text = [e.text.strip() for e in row.find_all('td')]\n",
    "            table_data_fixtures.append(row_text)\n",
    "\n",
    "        new_fixture_table_data = []\n",
    "        for x in list(zip(date_list,table_data_fixtures))[1:]:\n",
    "            fixture_row = []\n",
    "            for j in list(x):\n",
    "                for k in j:\n",
    "                    fixture_row.append(k)\n",
    "            new_fixtures_table_data.append(fixture_row)\n",
    "\n",
    "        fixtures_table = pd.DataFrame(new_fixtures_table_data, columns = header_data_fixtures )\n",
    "        fixtures_table = fixtures_table.replace({'': np.nan })\n",
    "        fixtures_table = fixtures_table[fixtures_table['Comp'] == 'Premier League']\n",
    "        fixtures_table = fixtures_table.drop(columns = ['Time','Comp','Round','Day','Attendance','Captain','Formation','Referee','Match Report','Notes'])\n",
    "        fixtures_table['Club'] = link_dictionary[url]\n",
    "        fixtures_table['Date'] = pd.to_datetime(fixtures_table ['Date'])\n",
    "\n",
    "    \n",
    "        # Saves fixture table as csv\n",
    "        fixtures_table.to_csv(fr'{full_path}\\{i}_{i+1}_{link_dictionary[url]}.csv')\n",
    "\n",
    "\n",
    "## PREMIER LEAGUE TABLE SCRIPT SCRAPES CURRENT TABLE ##\n",
    "\n",
    "if not os.getcwd().endswith('Football Forecasting Version 2'):\n",
    "    os.chdir(os.path.abspath(os.path.join(os.getcwd(), os.pardir)))\n",
    "    \n",
    "current_folder = os.getcwd()\n",
    "\n",
    "relative_folder = fr'{current_season}_{current_season + 1}_Matchweek'   \n",
    "\n",
    "full_path = os.path.join(current_folder, relative_folder)\n",
    "\n",
    "isExist = os.path.exists(full_path)\n",
    "\n",
    "if not isExist:\n",
    "    os.makedirs(full_path)\n",
    "\n",
    "table = pd.read_html(r'https://www.premierleague.com/tables?co=1&se=489&ha=-1')\n",
    "\n",
    "\n",
    "\n",
    "regular_table = pd.DataFrame(table[0])\n",
    "regular_table = regular_table.drop(columns = ['Next','Unnamed: 12'])\n",
    "regular_table ['Match Date'] = regular_table [1::2] ['Club'].str.split('-').str[1]\n",
    "regular_table ['Match Date'] = regular_table [1::2] ['Match Date'].str.split(' ').str[2:5]\n",
    "a = []\n",
    "for x in regular_table ['Match Date'][1::2]:\n",
    "    try:\n",
    "        a.append(' '.join(x))\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "regular_table = regular_table [::2]\n",
    "regular_table ['Match Date'] = a\n",
    "regular_table['Match Date'] = pd.to_datetime(regular_table ['Match Date'])\n",
    "regular_table.columns = ['Position', 'Club','Pl','W','D','L','GF','GA','GD','Pts','Form','Last Match Date']\n",
    "regular_table['Position'] = regular_table['Position'].str[:3].astype(int)\n",
    "regular_table['Code'] = regular_table['Club'].str[-3:]\n",
    "regular_table['Club'] = regular_table['Club'].str[:-3].str.strip()\n",
    "regular_table['Pl'] = regular_table['Pl'].astype(int)\n",
    "regular_table['W'] = regular_table['W'].astype(int)\n",
    "regular_table['D'] = regular_table['D'].astype(int)\n",
    "regular_table['L'] = regular_table['L'].astype(int)\n",
    "regular_table['GF'] = regular_table['GF'].astype(int)\n",
    "regular_table['GA'] = regular_table['GA'].astype(int)\n",
    "regular_table['GD'] = regular_table['GD'].astype(int)\n",
    "regular_table['Pts'] = regular_table['Pts'].astype(int)\n",
    "regular_table['Form'] = regular_table['Form'].str.replace(r'\\w{2,100}','',regex = True)\n",
    "regular_table['Form'] = regular_table['Form'].str.replace(r\"\\s+\",'',regex = True)\n",
    "regular_table['Form'] = regular_table['Form'].str.replace(r'[^a-zA-Z]','',regex = True)\n",
    "regular_table['Form']= regular_table['Form'].apply(lambda x: (x.count('W')*3 + x.count('D'))/len(x)) \n",
    "regular_table['Season'] = current_season \n",
    "\n",
    "regular_table.to_csv(fr'{full_path}\\{current_season}_{current_season + 1}_{current_matchweek -1}.csv')\n",
    "\n",
    "\n",
    "## CREATES MASTER HISTORICAL DATA ##\n",
    "if not os.getcwd().endswith('Football Forecasting Version 2'):\n",
    "    os.chdir(os.path.abspath(os.path.join(os.getcwd(), os.pardir)))\n",
    "\n",
    "dir_path = os.getcwd()\n",
    "\n",
    "\n",
    "# CREATES DICTIONARY OF THREE LETTER ON CLUBS\n",
    "\n",
    "res = []\n",
    "# Iterate directory\n",
    "for path in os.listdir(dir_path):\n",
    "    # check if current path is a folder\n",
    "    if os.path.isdir(os.path.join(dir_path, path)) and 'Matchweek' in path:\n",
    "        res.append(path)\n",
    "\n",
    "three_let_dict = {}\n",
    "for matchweek_folder in res:\n",
    "    os.chdir(fr'{dir_path}\\{matchweek_folder}')\n",
    "    a = pd.read_csv(random.choice(os.listdir(fr'{dir_path}\\{matchweek_folder}')))\n",
    "    for index, row in a.iterrows():\n",
    "        three_let_dict[row['Club'].strip()] =  row['Code']\n",
    "    os.chdir(dir_path)\n",
    "\n",
    "\n",
    "three_let_dict['Tottenham'] = three_let_dict.pop('Tottenham Hotspur')\n",
    "three_let_dict['Brighton'] = three_let_dict.pop('Brighton and Hove Albion')\n",
    "three_let_dict['Manchester Utd'] = three_let_dict.pop('Manchester United')\n",
    "three_let_dict['Newcastle Utd'] = three_let_dict.pop('Newcastle United')\n",
    "three_let_dict['West Ham'] = three_let_dict.pop('West Ham United')\n",
    "three_let_dict['Wolves'] = three_let_dict.pop('Wolverhampton Wanderers')\n",
    "three_let_dict[\"Nott'ham Forest\"] = three_let_dict.pop('Nottingham Forest')\n",
    "three_let_dict[\"Sheffield Utd\"] = three_let_dict.pop('Sheffield United')\n",
    "three_let_dict[\"Huddersfield\"] = three_let_dict.pop('Huddersfield Town')\n",
    "three_let_dict[\"West Brom\"] = three_let_dict.pop('West Bromwich Albion')\n",
    "\n",
    "\n",
    "\n",
    "### FIXTURE LIST\n",
    "\n",
    "res = []\n",
    "# Iterate directory\n",
    "for path in os.listdir(dir_path):\n",
    "    # check if current path is a folder\n",
    "    if os.path.isdir(os.path.join(dir_path, path)) and 'Fixture' in path:\n",
    "        res.append(path)\n",
    "print (res)\n",
    "df = pd.DataFrame()\n",
    "for fixtures in res:\n",
    "    os.chdir(fr'{dir_path}\\{fixtures}')\n",
    "    folder = os.getcwd()\n",
    "    list_of_files = os.listdir()\n",
    "    for i in list_of_files:\n",
    "        b = pd.read_csv(fr'{folder}\\{i}', index_col = 0)\n",
    "        b['Date'] = pd.to_datetime(b['Date'])\n",
    "        b['Club'] = b['Club'].map(three_let_dict)\n",
    "        b['Opponent'] = b['Opponent'].map(three_let_dict)\n",
    "        df = pd.concat([df,b])\n",
    "    os.chdir(dir_path)\n",
    "df = df.reset_index(drop = True)\n",
    "df = df.sort_values(by = ['Date'] )\n",
    "df = df.dropna()\n",
    "\n",
    "\n",
    "### SPI DATA\n",
    "\n",
    "res = []\n",
    "# Iterate directory\n",
    "for path in os.listdir(dir_path):\n",
    "    # check if current path is a folder\n",
    "    if os.path.isdir(os.path.join(dir_path, path)) and 'SPI' in path:\n",
    "        res.append(path)\n",
    "print (res)\n",
    "df1 = pd.DataFrame()\n",
    "for SPIdata in res:\n",
    "    os.chdir(fr'{dir_path}\\{SPIdata}')\n",
    "    folder = os.getcwd()\n",
    "    list_of_files = os.listdir()\n",
    "    for i in list_of_files:\n",
    "        b = pd.read_csv(fr'{folder}\\{i}', index_col=0)\n",
    "        b['date'] = pd.to_datetime(b['date'])\n",
    "        b['Season'] = int(i[:4])\n",
    "        b['team'] = b['team'].str.replace('Leicester', 'Leicester City')\n",
    "        b['team'] = b['team'].str.replace('Newcastle', 'Newcastle Utd')\n",
    "        b['team'] = b['team'].str.replace('Southamon', 'Southampton')\n",
    "        b['team'] = b['team'].str.replace('Norwich', 'Norwich City')\n",
    "        b['team'] = b['team'].str.replace('Man City', 'Manchester City')\n",
    "        b['team'] = b['team'].str.replace('Man United', 'Manchester Utd')\n",
    "        b['team'] = b['team'].str.replace('Nottm Forest', \"Nott'ham Forest\")\n",
    "        b['team'] = b['team'].map(three_let_dict)\n",
    "        df1 = pd.concat([df1,b])\n",
    "    os.chdir(dir_path)\n",
    "df1 = df1.reset_index(drop = True)\n",
    "df1 = df1.sort_values(by = ['date'] )\n",
    "\n",
    "\n",
    "### PREMIER LEAGUE TABLE\n",
    "res = []\n",
    "# Iterate directory\n",
    "for path in os.listdir(dir_path):\n",
    "    # check if current path is a folder\n",
    "    if os.path.isdir(os.path.join(dir_path, path)) and 'Matchweek' in path:\n",
    "        res.append(path)\n",
    "\n",
    "df2 = pd.DataFrame()\n",
    "for matchweek in res:\n",
    "    os.chdir(fr'{dir_path}\\{matchweek}')\n",
    "    folder = os.getcwd()\n",
    "    list_of_files = os.listdir()\n",
    "    for i in list_of_files:\n",
    "            a = pd.read_csv(fr'{folder}\\{i}', index_col = 0)\n",
    "            a['Season'] = int(matchweek[:4])\n",
    "            a['Last Match Date'] = pd.to_datetime(a['Last Match Date'])\n",
    "            a = a.drop (columns = ['Club','W','D','L','GF', 'GA', 'GD'])\n",
    "            df2 = pd.concat([df2,a])\n",
    "    os.chdir(dir_path)\n",
    "\n",
    "df2 = df2.sort_values(by = ['Last Match Date'])\n",
    "\n",
    "\n",
    "fixture_fixture_merge  = pd.merge_asof(left=df,right=df,left_on = ['Date'], right_on = ['Date'], left_by = ['Club'], right_by = ['Opponent'], direction='nearest')\n",
    "fixture_fixture_merge = fixture_fixture_merge.drop(columns = ['Venue_y', 'Result_y','Opponent_y','Club_y'])\n",
    "matchweek_fixture_merge_1 = pd.merge_asof(left=fixture_fixture_merge ,right=df2,left_on = ['Date'], right_on = ['Last Match Date'], left_by = ['Club_x'], right_by = ['Code'], direction='nearest')\n",
    "matchweek_fixture_merge_1 = matchweek_fixture_merge_1.drop (columns = ['Last Match Date', 'Code']) \n",
    "matchweek_fixture_merge_2 = pd.merge_asof(left=matchweek_fixture_merge_1,right=df2,left_on = ['Date'], right_on = ['Last Match Date'], left_by = ['Opponent_x'], right_by = ['Code'], direction='nearest')\n",
    "matchweek_fixture_merge_2 = matchweek_fixture_merge_2.drop (columns = ['Season_x','Last Match Date', 'Code']) \n",
    "matchweek_fixture_merge_1 = pd.merge_asof(left=fixture_fixture_merge ,right=df2,left_on = ['Date'], right_on = ['Last Match Date'], left_by = ['Club_x'], right_by = ['Code'], direction='nearest')\n",
    "matchweek_fixture_merge_1 = matchweek_fixture_merge_1.drop (columns = ['Last Match Date', 'Code']) \n",
    "matchweek_fixture_merge_2 = pd.merge_asof(left=matchweek_fixture_merge_1,right=df2,left_on = ['Date'], right_on = ['Last Match Date'], left_by = ['Opponent_x'], right_by = ['Code'], direction='nearest')\n",
    "matchweek_fixture_merge_2 = matchweek_fixture_merge_2.drop (columns = ['Season_x','Last Match Date', 'Code']) \n",
    "rename_columns = {'Venue_x' : 'Venue', 'Result_x' : 'Result', 'Club_x':'Club', 'Season_x' : 'Season', 'Opponent_x': 'Opp'}\n",
    "spi_everything_merge_1 = pd.merge_asof(left=matchweek_fixture_merge_2, right=df1, left_on = ['Date'], right_on = ['date'], left_by = ['Club_x'], right_by = ['team'], direction='nearest')\n",
    "spi_everything_merge_1 = spi_everything_merge_1.drop (columns = ['team','date', 'Season_y']) \n",
    "spi_everything_merge_2 = pd.merge_asof(left=spi_everything_merge_1 , right=df1, left_on = ['Date'], right_on = ['date'], left_by = ['Opponent_x'], right_by = ['team'], direction='nearest')\n",
    "spi_everything_merge_2 = spi_everything_merge_2.drop (columns = ['team','date', 'Season_y', 'GF_y', 'GA_y', 'xG_y', 'xGA_y']) \n",
    "df_final = spi_everything_merge_2.rename(rename_columns, axis = 'columns')\n",
    "\n",
    "df_final = df_final.sort_values(by = ['Club','Season','Date'])\n",
    "df_final['Pl_x'] = df_final.groupby(['Club','Season'])['Pl_x'].shift(1)\n",
    "df_final['Position_x'] = df_final.groupby(['Club','Season'])['Position_x'].shift(1)\n",
    "df_final['Pts_x'] = df_final.groupby(['Club','Season'])['Pts_x'].shift(1)\n",
    "df_final['Form_x'] = df_final.groupby(['Club','Season'])['Pts_x'].shift(1)\n",
    "\n",
    "\n",
    "df_final = df_final.sort_values(by = ['Opp','Season','Date'])\n",
    "df_final['Pl_y'] = df_final.groupby(['Opp','Season'])['Pl_y'].shift(1)\n",
    "df_final['Position_y'] = df_final.groupby(['Opp','Season'])['Position_y'].shift(1)\n",
    "df_final['Pts_y'] = df_final.groupby(['Opp','Season'])['Pts_y'].shift(1)\n",
    "df_final['Form_y'] = df_final.groupby(['Opp','Season'])['Pts_y'].shift(1)\n",
    "\n",
    "df_final = df_final.sort_values(by = ['Club','Season','Date'])\n",
    "\n",
    "df_final = df_final.dropna()\n",
    "\n",
    "if not os.getcwd().endswith('Football Forecasting Version 2'):\n",
    "    os.chdir(os.path.abspath(os.path.join(os.getcwd(), os.pardir)))\n",
    "\n",
    "os.chdir(fr'{dir_path}\\{current_season}_{current_season + 1}_Clean_Data')\n",
    "\n",
    "today = date.today()\n",
    "\n",
    "df_final.to_csv(fr'{current_season}_{current_season + 1}_{today.strftime(\"%b%d\")}_historical_data.csv')\n",
    "\n",
    "## PREPARES PREDICTION TABLE ###\n",
    "\n",
    "if not os.getcwd().endswith('Football Forecasting Version 2'):\n",
    "    os.chdir(os.path.abspath(os.path.join(os.getcwd(), os.pardir)))\n",
    "\n",
    "dir_path = os.getcwd()\n",
    "\n",
    "### FIXTURE LIST\n",
    "\n",
    "res = []\n",
    "# Iterate directory\n",
    "for path in os.listdir(dir_path):\n",
    "    # check if current path is a folder\n",
    "    if os.path.isdir(os.path.join(dir_path, path)) and 'Fixture' in path:\n",
    "        res.append(path)\n",
    "print (res)\n",
    "df = pd.DataFrame()\n",
    "for fixtures in res:\n",
    "    os.chdir(fr'{dir_path}\\{fixtures}')\n",
    "    folder = os.getcwd()\n",
    "    list_of_files = os.listdir()\n",
    "    for i in list_of_files:\n",
    "        b = pd.read_csv(fr'{folder}\\{i}', index_col = 0)\n",
    "        b['Date'] = pd.to_datetime(b['Date'])\n",
    "        b['Club'] = b['Club'].map(three_let_dict)\n",
    "        b['Opponent'] = b['Opponent'].map(three_let_dict)\n",
    "        b = b[b['Date'] > np.datetime64('today')].iloc[:1]\n",
    "        df = pd.concat([df,b])\n",
    "    os.chdir(dir_path)\n",
    "df = df.reset_index(drop = True)\n",
    "df = df.sort_values(by = ['Date'] )\n",
    "df = df.reset_index(drop = True)\n",
    "\n",
    "\n",
    "\n",
    "fixture_fixture_merge  = pd.merge_asof(left=df,right=df,left_on = ['Date'], right_on = ['Date'], left_by = ['Club'], right_by = ['Opponent'], direction='nearest')\n",
    "fixture_fixture_merge = fixture_fixture_merge.drop(columns = ['Venue_y', 'Result_y','Opponent_y','Club_y'])\n",
    "matchweek_fixture_merge_1 = pd.merge_asof(left=fixture_fixture_merge ,right=df2,left_on = ['Date'], right_on = ['Last Match Date'], left_by = ['Club_x'], right_by = ['Code'], direction='nearest')\n",
    "matchweek_fixture_merge_1 = matchweek_fixture_merge_1.drop (columns = ['Last Match Date', 'Code']) \n",
    "matchweek_fixture_merge_2 = pd.merge_asof(left=matchweek_fixture_merge_1,right=df2,left_on = ['Date'], right_on = ['Last Match Date'], left_by = ['Opponent_x'], right_by = ['Code'], direction='nearest')\n",
    "matchweek_fixture_merge_2 = matchweek_fixture_merge_2.drop (columns = ['Season_x','Last Match Date', 'Code']) \n",
    "spi_everything_merge_1 = pd.merge_asof(left=matchweek_fixture_merge_2, right=df1, left_on = ['Date'], right_on = ['date'], left_by = ['Club_x'], right_by = ['team'], direction='nearest')\n",
    "spi_everything_merge_1 = spi_everything_merge_1.drop (columns = ['team','date', 'Season_y']) \n",
    "spi_everything_merge_2 = pd.merge_asof(left=spi_everything_merge_1 , right=df1, left_on = ['Date'], right_on = ['date'], left_by = ['Opponent_x'], right_by = ['team'], direction='nearest')\n",
    "spi_everything_merge_2 = spi_everything_merge_2.drop (columns = ['team','date', 'Season_y', 'GF_y', 'GA_y', 'xG_y', 'xGA_y']) \n",
    "\n",
    "rename_columns = {'Venue_x' : 'Venue', 'Result_x' : 'Result', 'Club_x':'Club', 'Season_x' : 'Season', 'Opponent_x': 'Opp'}\n",
    "\n",
    "df_final = spi_everything_merge_2.rename(rename_columns, axis = 'columns')\n",
    "\n",
    "\n",
    "if not os.getcwd().endswith('Football Forecasting Version 2'):\n",
    "    os.chdir(os.path.abspath(os.path.join(os.getcwd(), os.pardir)))\n",
    "\n",
    "os.chdir(fr'{dir_path}\\{current_season}_{current_season + 1}_Clean_Data')\n",
    "\n",
    "df_final.to_csv(fr'{current_season}_{current_season + 1}_{today.strftime(\"%b%d\")}_matchweek_data.csv')\n",
    "\n",
    "### REGRESSION PREDICTOR ###\n",
    "\n",
    "if not os.getcwd().endswith('Football Forecasting Version 2'):\n",
    "    os.chdir(os.path.abspath(os.path.join(os.getcwd(), os.pardir)))\n",
    "\n",
    "dir_path = os.getcwd()\n",
    "\n",
    "df_train = pd.read_csv(fr'{dir_path}\\{current_season}_{current_season + 1}_Clean_Data\\{current_season}_{current_season + 1}_{today.strftime(\"%b%d\")}_historical_data.csv', index_col = 0)\n",
    "\n",
    "df_pred = pd.read_csv(fr'{dir_path}\\{current_season}_{current_season + 1}_Clean_Data\\{current_season}_{current_season + 1}_{today.strftime(\"%b%d\")}_matchweek_data.csv', index_col = 0)\n",
    "\n",
    "\n",
    "df = pd.concat([df_train,df_pred])\n",
    "df = df.sort_values(by = ['Club','Season','Date',])\n",
    "df=df.reset_index(drop = True)\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "\n",
    "## RESULT ENCODING ##\n",
    "def encode_result(x):\n",
    "    if x['Result'] == 'W':\n",
    "        val= 2\n",
    "    elif x['Result'] == 'D':\n",
    "        val= 1\n",
    "    else:\n",
    "        val = 0\n",
    "    return val\n",
    "\n",
    "df['Result'] = df.apply(encode_result, axis = 1) \n",
    "\n",
    "#POINTS DIFF#\n",
    "df['Points_Diff'] = (df['Pts_x']/df['Pl_x'] - df['Pts_y']/df['Pl_y'])/3\n",
    "\n",
    "\n",
    "##SPI Diff##\n",
    "df['SPI_Diff'] = df['spi_x'] - df['spi_y']\n",
    "df['SPI_Diff'] = (df['SPI_Diff'] - df.groupby(['Season'])['SPI_Diff'].transform(min))/(df.groupby(['Season'])['SPI_Diff'].transform(max) - df.groupby(['Season'])['SPI_Diff'].transform(min))\n",
    "df['Off_Diff'] = df['off_x'] - df['off_y']\n",
    "df['Off_Diff'] = (df['Off_Diff'] - df.groupby(['Season'])['Off_Diff'].transform(min))/(df.groupby(['Season'])['Off_Diff'].transform(max) - df.groupby(['Season'])['Off_Diff'].transform(min))\n",
    "df['Def_Diff'] = df['def_x'] - df['def_y']\n",
    "df['Def_Diff'] = (df['Def_Diff'] - df.groupby(['Season'])['Def_Diff'].transform(min))/(df.groupby(['Season'])['Def_Diff'].transform(max) - df.groupby(['Season'])['Def_Diff'].transform(min))\n",
    "\n",
    "##FORM##\n",
    "df['Form_Diff'] = (df['Form_x'] - df['Form_y'])/15\n",
    "\n",
    "# Creating form for goals and goals conceded and expected values for last 5 games\n",
    "df['Avg_GF_last_5'] = df.groupby(['Club','Season'])['GF_x'].shift(1)\n",
    "df['Avg_GF_last_5'] = df.groupby(['Club','Season'])['Avg_GF_last_5'].rolling(5).mean().reset_index([0,1],drop=True)\n",
    "df['Avg_GA_last_5'] = df.groupby(['Club','Season'])['GA_x'].shift(1)\n",
    "df['Avg_GA_last_5'] = df.groupby(['Club','Season'])['Avg_GA_last_5'].rolling(5).mean().reset_index([0,1],drop=True)\n",
    "df['Avg_xG_last_5'] = df.groupby(['Club','Season'])['xG_x'].shift(1)\n",
    "df['Avg_xG_last_5'] = df.groupby(['Club','Season'])['Avg_xG_last_5'].rolling(5).mean().reset_index([0,1],drop=True)\n",
    "df['Avg_xGA_last_5'] = df.groupby(['Club','Season'])['xGA_x'].shift(1)\n",
    "df['Avg_xGA_last_5'] = df.groupby(['Club','Season'])['Avg_xGA_last_5'].rolling(5).mean().reset_index([0,1],drop=True)\n",
    "df['Avg_Poss_last_5'] = df.groupby(['Club','Season'])['Poss_x'].shift(1)\n",
    "df['Avg_Poss_last_5'] = df.groupby(['Club','Season'])['Avg_Poss_last_5'].rolling(5).mean().reset_index([0,1],drop=True)\n",
    "\n",
    "#Standardisation\n",
    "df['Avg_GF_last_5'] = (df['Avg_GF_last_5'] - df.groupby(['Season'])['Avg_GF_last_5'].transform(min))/(df.groupby(['Season'])['Avg_GF_last_5'].transform(max) - df.groupby(['Season'])['Avg_GF_last_5'].transform(min))\n",
    "df['Avg_GA_last_5'] = (df['Avg_GA_last_5'] - df.groupby(['Season'])['Avg_GA_last_5'].transform(min))/(df.groupby(['Season'])['Avg_GA_last_5'].transform(max) - df.groupby(['Season'])['Avg_GA_last_5'].transform(min))\n",
    "df['Avg_xG_last_5'] = (df['Avg_xG_last_5'] - df.groupby(['Season'])['Avg_xG_last_5'].transform(min))/(df.groupby(['Season'])['Avg_xG_last_5'].transform(max) - df.groupby(['Season'])['Avg_xG_last_5'].transform(min))\n",
    "df['Avg_xGA_last_5'] = (df['Avg_xGA_last_5'] - df.groupby(['Season'])['Avg_xGA_last_5'].transform(min))/(df.groupby(['Season'])['Avg_xGA_last_5'].transform(max) - df.groupby(['Season'])['Avg_xGA_last_5'].transform(min))\n",
    "df['Avg_Poss_last_5'] = (df['Avg_Poss_last_5'] - df.groupby(['Season'])['Avg_Poss_last_5'].transform(min))/(df.groupby(['Season'])['Avg_Poss_last_5'].transform(max) - df.groupby(['Season'])['Avg_Poss_last_5'].transform(min))\n",
    "\n",
    "##SEASON STATS##\n",
    "df['Avg_GF_season'] = df.groupby(['Club','Season'])['GF_x'].shift(1)\n",
    "df['Avg_GF_season'] = df.groupby(['Season'])['Avg_GF_season'].expanding(1).mean().reset_index([0],drop=True)\n",
    "df['Avg_GA_season'] = df.groupby(['Club','Season'])['GA_x'].shift(1)\n",
    "df['Avg_GA_season'] = df.groupby(['Season'])['Avg_GA_season'].expanding(1).mean().reset_index([0],drop=True)\n",
    "df['Avg_xG_season'] = df.groupby(['Club','Season'])['xG_x'].shift(1)\n",
    "df['Avg_xG_season'] = df.groupby(['Season'])['Avg_xG_season'].expanding(1).mean().reset_index([0],drop=True)\n",
    "df['Avg_xGA_season'] = df.groupby(['Club','Season'])['xGA_x'].shift(1)\n",
    "df['Avg_xGA_season'] = df.groupby(['Season'])['Avg_xGA_season'].expanding(1).mean().reset_index([0],drop=True)\n",
    "df['Avg_Poss_season'] = df.groupby(['Club','Season'])['Poss_x'].shift(1)\n",
    "df['Avg_Poss_season'] = df.groupby(['Season'])['Avg_Poss_season'].expanding(1).mean().reset_index([0],drop=True)\n",
    "\n",
    "#Standardisation\n",
    "df['Avg_GF_season'] = (df['Avg_GF_season'] - df.groupby(['Season'])['Avg_GF_season'].transform(min))/(df.groupby(['Season'])['Avg_GF_season'].transform(max) - df.groupby(['Season'])['Avg_GF_season'].transform(min))\n",
    "df['Avg_GA_season'] = (df['Avg_GA_season'] - df.groupby(['Season'])['Avg_GA_season'].transform(min))/(df.groupby(['Season'])['Avg_GA_season'].transform(max) - df.groupby(['Season'])['Avg_GA_season'].transform(min))\n",
    "df['Avg_xG_season'] = (df['Avg_xG_season'] - df.groupby(['Season'])['Avg_xG_season'].transform(min))/(df.groupby(['Season'])['Avg_xG_season'].transform(max) - df.groupby(['Season'])['Avg_xG_season'].transform(min))\n",
    "df['Avg_xGA_season'] = (df['Avg_xGA_season'] - df.groupby(['Season'])['Avg_xGA_season'].transform(min))/(df.groupby(['Season'])['Avg_xGA_season'].transform(max) - df.groupby(['Season'])['Avg_xGA_season'].transform(min))\n",
    "df['Avg_Poss_season'] = (df['Avg_Poss_season'] - df.groupby(['Season'])['Avg_Poss_season'].transform(min))/(df.groupby(['Season'])['Avg_Poss_season'].transform(max) - df.groupby(['Season'])['Avg_Poss_season'].transform(min))\n",
    "\n",
    "##AGAINST OPPONENT##\n",
    "df['Avg_GF_Opp'] = df.groupby(['Club','Opp'])['GF_x'].shift(1)\n",
    "df['Avg_GF_Opp'] = df.groupby(['Club','Opp'])['Avg_GF_Opp'].rolling(2).mean().reset_index([0,1],drop=True)\n",
    "df['Avg_GA_Opp'] = df.groupby(['Club','Opp'])['GA_x'].shift(1)\n",
    "df['Avg_GA_Opp'] = df.groupby(['Club','Opp'])['Avg_GA_Opp'].rolling(2).mean().reset_index([0,1],drop=True)\n",
    "df['Avg_xG_Opp'] = df.groupby(['Club','Opp'])['xG_x'].shift(1)\n",
    "df['Avg_xG_Opp'] = df.groupby(['Club','Opp'])['Avg_xG_Opp'].rolling(2).mean().reset_index([0,1],drop=True)\n",
    "df['Avg_xGA_Opp'] = df.groupby(['Club','Opp'])['xGA_x'].shift(1)\n",
    "df['Avg_xGA_Opp'] = df.groupby(['Club','Opp'])['Avg_xGA_Opp'].rolling(2).mean().reset_index([0,1],drop=True)\n",
    "df['Avg_Poss_Opp'] = df.groupby(['Club','Opp'])['Poss_x'].shift(1)\n",
    "df['Avg_Poss_Opp'] = df.groupby(['Club','Opp'])['Avg_Poss_Opp'].rolling(2).mean().reset_index([0,1],drop=True)\n",
    "\n",
    "#Standardisation\n",
    "df['Avg_GF_Opp'] = (df['Avg_GF_Opp'] - df.groupby(['Opp'])['Avg_GF_Opp'].transform(min))/(df.groupby(['Opp'])['Avg_GF_Opp'].transform(max) - df.groupby(['Opp'])['Avg_GF_Opp'].transform(min))\n",
    "df['Avg_GA_Opp'] = (df['Avg_GA_Opp'] - df.groupby(['Opp'])['Avg_GA_Opp'].transform(min))/(df.groupby(['Opp'])['Avg_GA_Opp'].transform(max) - df.groupby(['Opp'])['Avg_GA_Opp'].transform(min))\n",
    "df['Avg_xG_Opp'] = (df['Avg_xG_Opp'] - df.groupby(['Opp'])['Avg_xG_Opp'].transform(min))/(df.groupby(['Opp'])['Avg_xG_Opp'].transform(max) - df.groupby(['Opp'])['Avg_xG_Opp'].transform(min))\n",
    "df['Avg_xGA_Opp'] = (df['Avg_xGA_Opp'] - df.groupby(['Opp'])['Avg_xGA_Opp'].transform(min))/(df.groupby(['Opp'])['Avg_xGA_Opp'].transform(max) - df.groupby(['Opp'])['Avg_xGA_Opp'].transform(min))\n",
    "df['Avg_Poss_Opp'] = (df['Avg_Poss_Opp'] - df.groupby(['Opp'])['Avg_Poss_Opp'].transform(min))/(df.groupby(['Opp'])['Avg_Poss_Opp'].transform(max) - df.groupby(['Opp'])['Avg_Poss_Opp'].transform(min))\n",
    "\n",
    "\n",
    "df_test = df[df['Date'] < np.datetime64('today')]\n",
    "df_pred = df[df['Date'] >  np.datetime64('today')]\n",
    "df_pred['GF_x'] = 0\n",
    "df_pred['GA_x'] = 0\n",
    "df_poo = df_pred\n",
    "\n",
    "\n",
    "unwanted_columns = ['Date','Opp','Result','GF_x', 'xG_x', 'xGA_x',\n",
    "       'Poss_x', 'Club', 'Poss_y', 'Position_x', 'Pl_x', 'Pts_x', 'Form_x',\n",
    "       'Position_y', 'Pl_y', 'Pts_y', 'Form_y', 'spi_x', 'off_x', 'def_x',\n",
    "       'Season', 'spi_y', 'off_y','def_y']\n",
    "df_test_1 = df_test.drop(columns = unwanted_columns)\n",
    "df_pred_1 = df_pred.drop(columns = unwanted_columns)\n",
    "df_test_1 = df_test_1.dropna()\n",
    "df_pred_1 = df_pred_1.dropna()\n",
    "\n",
    "df_test_1= pd.get_dummies(df_test_1, columns=['Venue'])\n",
    "df_pred_1= pd.get_dummies(df_pred_1, columns=['Venue'])\n",
    "\n",
    "boo = df_test_1.drop(columns = 'GA_x')\n",
    "\n",
    "X_train_1 = df_test_1[boo.columns]\n",
    "y_train_1 = df_test_1['GA_x']\n",
    "\n",
    "X_test_1 = df_pred_1[boo.columns]\n",
    "\n",
    "rfr = RandomForestRegressor(n_estimators = 250, max_depth = 3, random_state = 0)\n",
    "rfr.fit(X_train_1, y_train_1)\n",
    "y_pred_1 = rfr.predict(X_test_1)\n",
    "\n",
    "\n",
    "unwanted_columns = ['Date','Opp','Result','GA_x', 'xG_x', 'xGA_x',\n",
    "       'Poss_x', 'Club', 'Poss_y', 'Position_x', 'Pl_x', 'Pts_x', 'Form_x',\n",
    "       'Position_y', 'Pl_y', 'Pts_y', 'Form_y', 'spi_x', 'off_x', 'def_x',\n",
    "       'Season', 'spi_y', 'off_y','def_y']\n",
    "df_test = df_test.drop(columns = unwanted_columns)\n",
    "df_pred = df_pred.drop(columns = unwanted_columns)\n",
    "df_test = df_test.dropna()\n",
    "df_pred = df_pred.dropna()\n",
    "\n",
    "df_test.columns\n",
    "df_test= pd.get_dummies(df_test, columns=['Venue'])\n",
    "df_pred= pd.get_dummies(df_pred, columns=['Venue'])\n",
    "\n",
    "boo = df_test.drop(columns = 'GF_x')\n",
    "\n",
    "X_train = df_test[boo.columns]\n",
    "y_train = df_test['GF_x']\n",
    "\n",
    "X_test = df_pred[boo.columns]\n",
    "\n",
    "rfr = RandomForestRegressor(n_estimators = 90, max_depth = 3, random_state = 0)\n",
    "rfr.fit(X_train, y_train)\n",
    "y_pred = rfr.predict(X_test)\n",
    "\n",
    "df_poo = df_poo[['Season','Club','Opp','Venue']]\n",
    "a = pd.DataFrame(y_pred, columns = ['GF'], index = X_test.index)\n",
    "b = pd.DataFrame(y_pred_1, columns = ['GA'], index = X_test_1.index)\n",
    "c = pd.merge(df_poo,a, left_index=True, right_index=True)\n",
    "d1 = pd.merge(c,b, left_index=True, right_index=True)\n",
    "d2 = pd.merge(d1,d1, left_on = 'Club', right_on = 'Opp')\n",
    "d2 = d2.drop(columns = ['Season_y','Club_y','Opp_y','Venue_y'])\n",
    "\n",
    "d2['GF'] = (d2['GF_x'] + d2['GA_y']) /2\n",
    "d2['GA'] = (d2['GF_y'] + d2['GA_x']) /2\n",
    "d2 = d2.drop(columns = ['GF_x','GA_x','GF_y','GA_y'])\n",
    "\n",
    "d3 = d2.drop (columns = ['Venue_x','GA'])\n",
    "\n",
    "\n",
    "for score in range (6):\n",
    "    d3['Score' + str(score)] = (d3['GF'] ** score * np.exp(- d3['GF']))/np.math.factorial(score)\n",
    "\n",
    "d4 = pd.merge(d3,d3, left_on = 'Club_x', right_on = 'Opp_x')\n",
    "\n",
    "score_list = []\n",
    "\n",
    "win_list = []\n",
    "draw_list = []\n",
    "loss_list = []\n",
    "\n",
    "for i in range (6):\n",
    "    for j in range (6):\n",
    "        d4[fr'{i} - {j}'] = d4[fr'Score{i}_x'] * d4[fr'Score{j}_y']\n",
    "        score_list.append(fr'{i} - {j}')\n",
    "\n",
    "        if i > j:\n",
    "            win_list.append(list(d4[fr'Score{i}_x'] * d4[fr'Score{j}_y']))\n",
    "        elif i == j:\n",
    "            draw_list.append(list(d4[fr'Score{i}_x'] * d4[fr'Score{j}_y']))\n",
    "        else:\n",
    "            loss_list.append(list(d4[fr'Score{i}_x'] * d4[fr'Score{j}_y']))\n",
    "\n",
    "\n",
    "d4[score_list].idxmax(axis = 1)\n",
    "\n",
    "d2['Most likely score'] = list(d4[score_list].idxmax(axis = 1))\n",
    "\n",
    "win_list = [sum(i) for i in list(zip(*win_list))]\n",
    "draw_list = [sum(i) for i in list(zip(*draw_list))]\n",
    "loss_list = [sum(i) for i in list(zip(*loss_list))]\n",
    "\n",
    "d2['win_prob'] = win_list\n",
    "d2['draw_prob'] = draw_list\n",
    "d2['loss_prob'] = loss_list\n",
    "\n",
    "if not os.getcwd().endswith('Football Forecasting Version 2'):\n",
    "    os.chdir(os.path.abspath(os.path.join(os.getcwd(), os.pardir)))\n",
    "\n",
    "current_folder = os.getcwd()\n",
    "\n",
    "relative_folder = fr'{current_season}_{current_season + 1}_Match_Predictions'   \n",
    "\n",
    "full_path = os.path.join(current_folder, relative_folder)\n",
    "\n",
    "d2.to_csv(fr'{full_path}\\{current_season}_{current_season + 1}_{today.strftime(\"%b%d\")}_predictions.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
